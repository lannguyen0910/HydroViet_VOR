settings:
  data: ""
  project_name: "" # also the folder name of the dataset that under ./data folder
  train_imgs: "train_data"
  val_imgs: "val_data"
  test_imgs: "test_data"

  #################   TRAINING CONFIG   ###################

  model_arch: "efficientnet_b1" #[]

  pretrained_backbone: "" # Pretrained backbone

  gpu_devices: "0" # supports multi-gpus
  num_epochs: 100
  batch_size: 16
  num_workers: 2

  image_size: [256, 256] # should be square to prevent bugs [512, 640, 768, 896, 1024, 1280, 1280, 1536, 1536]
  keep_ratio: False # whether to use resize padding

  mixup: True

  # learning rate policy
  lr_policy:
    name: "adam" #[adam|sgd] (adam means AdamW optimizer)
    lr: 0.001 #[adam: 1e-3 | sgd: 1e-2]
    momentum: 0.937
    weight_decay: 0.0005

  lr_scheduler:
    name:
      "cosine" #[plateau | cosine | 1cycle-yolo | 1cycle]
      # if need to specify more scheduler arguments, do it here

  # Apex sync batch normalization (could be helpful)
  syncBN: True

  # gradient accumulation
  mixed_precision: True # whether to use nvidia apex
  total_accumulate_steps: 64 # step * batch_size, not use if equal 0

  # Test time augmentation
  tta: False # whether to use TTA while validation
